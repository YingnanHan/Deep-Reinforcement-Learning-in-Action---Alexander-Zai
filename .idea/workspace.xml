<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="db5997fe-08b4-47f5-9f96-e6576667bebe" name="Default Changelist" comment="" />
    <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileEditorManager">
    <leaf SIDE_TABS_SIZE_LIMIT_KEY="300" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Python Script" />
      </list>
    </option>
  </component>
  <component name="FindInProjectRecents">
    <findStrings>
      <find>test</find>
    </findStrings>
  </component>
  <component name="HighlightingSettingsPerFile">
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/05.找出最佳動作.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/08.使用softmax解決多臂拉霸機問題.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/03.建構模型.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/07.softmax函式.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/05.進程同步 -- 加鎖.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/06.進程池化基於Pool.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.03 使用OpenAI Gym/01.使用OpenAI Gym.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/04.更新record內容.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.04 REINFORCE演算法/01.reinforce演算法.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/07.基於Queue進行進程通信.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/03.對撞墻進行避免.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/01.簡單案例 -- 平方 立方計算.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/02.打印運行中進程的ID.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/03.數據共享.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/02.設定ε值以及不同拉霸機的中獎率.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/01.利用平均(期望)獎金找出最佳動作.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter01 強化式學習的基本觀念/01.Pre.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/01.目標網絡.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/04.6X6方格遊戲下的DQN.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/03.把中獎幾率轉化成中獎金額.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/Gridworld.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/04.測試Q網路.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/02.自動微分.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.03 避免灾难性失忆的发生 经验回放/01.包含經驗回放的DQN.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/04.進程同步 -- 不設置同步機制.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/02.測試網絡.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/08.基於共有的Queue進行通信.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/01.建立一個Gridworld遊戲.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/03.運算圖.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/GridBoard.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/06.解決多臂拉霸機問題.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/01.Pytorch中的張量.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.04 解决广告推送问题/01.解决广告推送问题.py" root0="SKIP_HIGHLIGHTING" />
    <setting file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/02.利用神經網絡扮演Q函數的角色.py" root0="SKIP_HIGHLIGHTING" />
  </component>
  <component name="IdeDocumentHistory">
    <option name="CHANGED_PATHS">
      <list>
        <option value="$PROJECT_DIR$/Chapter01 強化式學習的基本觀念/00.Pre.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/.idea/01.利用平均(期望)獎金找出最佳動作.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/01.利用平均(期望)獎金找出最佳動作.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.設定ε值以及不同拉霸機的中獎率.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/03.把中獎幾率轉化成中獎金額.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/05.解決多臂拉霸機問題.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/04.更新record內容.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/05.找出最佳動作.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/06.解決多臂拉霸機問題.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/多臂拉霸機問題/07.softmax函式.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/多臂拉霸機問題/08.使用softmax解決多臂拉霸機問題.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/01.Pytorch的自動微分與模型建構.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/02.自動微分.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/03.建構模型.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/07.softmax.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/07.softmax函式.py" />
        <option value="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/04.解决广告推送问题.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/01.建立一個Gridworld遊戲.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.運算圖.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/02.利用神經網絡扮演Q函數的角色.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/1.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/04.測試Q網路.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/05.包含經驗回放的DQN.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/1.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/01.目標網絡.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/04.測試Q網路.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/02.測試網絡.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/03.對撞墻進行避免.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/04.4X4方格遊戲下的DQN.py" />
        <option value="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/04.6X6方格遊戲下的DQN.py" />
        <option value="$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/.idea/test.py" />
        <option value="$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/01.使用OpenAI Gym.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/01.example01.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/02.打印運行中進程的ID.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/03.數據共享.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/04.進程同步 -- 不設置同步機制.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/05.進程同步 -- 加鎖.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/06.進程池化基於Pool.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/07.基於Queue進行進程通信.py" />
        <option value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/08.multiprocessing Manager.py" />
        <option value="$PROJECT_DIR$/Refered Testing/Other.py" />
        <option value="$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.04 REINFORCE演算法/01.reinforce演算法.py" />
        <option value="$PROJECT_DIR$/Chapter05 演員評論家模型與分佈式訓練/test.py" />
        <option value="$PROJECT_DIR$/Chapter05 演員評論家模型與分佈式訓練/Note" />
      </list>
    </option>
  </component>
  <component name="ProjectFrameBounds" extendedState="6">
    <option name="x" value="2419" />
    <option name="y" value="142" />
    <option name="width" value="819" />
    <option name="height" value="839" />
  </component>
  <component name="ProjectView">
    <navigator currentView="Scope" currentSubView="Scope 'Project Files'; set:Project Files; class com.intellij.psi.search.scope.ProjectFilesScope" proportions="" version="1">
      <foldersAlwaysOnTop value="true" />
    </navigator>
    <panes>
      <pane id="Scope">
        <subPane subId="Scope 'Project Files'; set:Project Files; class com.intellij.psi.search.scope.ProjectFilesScope">
          <expand>
            <path>
              <item name="11.深度強化式學習" type="3d21c010:ScopeViewTreeModel$ProjectNode" />
              <item name="C:\Users\20613\Desktop\11.深度強化式學習" type="442cc68d:ScopeViewTreeModel$RootNode" />
            </path>
          </expand>
          <select />
        </subPane>
      </pane>
      <pane id="ProjectPane">
        <subPane>
          <expand>
            <path>
              <item name="11.深度強化式學習" type="b2602c69:ProjectViewProjectNode" />
              <item name="11.深度強化式學習" type="462c0819:PsiDirectoryNode" />
            </path>
          </expand>
          <select />
        </subPane>
      </pane>
    </panes>
  </component>
  <component name="PropertiesComponent">
    <property name="WebServerToolWindowFactoryState" value="false" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$" />
    <property name="nodejs_interpreter_path.stuck_in_default_project" value="undefined stuck path" />
    <property name="nodejs_npm_path_reset_for_default_project" value="true" />
    <property name="restartRequiresConfirmation" value="false" />
    <property name="settings.editor.selected.configurable" value="com.jetbrains.python.configuration.PyIntegratedToolsModulesConfigurable" />
  </component>
  <component name="ReadonlyStatusHandler">
    <option name="SHOW_DIALOG" value="false" />
  </component>
  <component name="RecentsManager">
    <key name="MoveFile.RECENT_KEYS">
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Chapter05 演員評論家模型與分佈式訓練" />
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Chapter04 利用策略梯度法選擇最佳策略\04.03 使用OpenAI Gym" />
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Refered Testing\01.multiprocessing的使用" />
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Refered Testing" />
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Chapter02 模型化強化式學習問題 馬爾科夫決策過程\02.04 解决广告推送问题" />
    </key>
    <key name="CopyFile.RECENT_KEYS">
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Chapter04 利用策略梯度法選擇最佳策略" />
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Chapter03 Deep Q-Network\03.04 使用目標網絡來提升學習的穩定性" />
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Chapter03 Deep Q-Network\03.03 避免灾难性失忆的发生 经验回放" />
      <recent name="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Chapter03 Deep Q-Network" />
    </key>
  </component>
  <component name="RunDashboard">
    <option name="ruleStates">
      <list>
        <RuleState>
          <option name="name" value="ConfigurationTypeDashboardGroupingRule" />
        </RuleState>
        <RuleState>
          <option name="name" value="StatusDashboardGroupingRule" />
        </RuleState>
      </list>
    </option>
  </component>
  <component name="RunManager" selected="Python.01.reinforce演算法">
    <configuration name="01.reinforce演算法" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="12.深度強化式學習(自學習代碼)" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.04 REINFORCE演算法" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.04 REINFORCE演算法/01.reinforce演算法.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="08.基於共有的Queue進行通信" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="12.深度強化式學習(自學習代碼)" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/08.基於共有的Queue進行通信.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="08.multiprocessing Manager" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="12.深度強化式學習(自學習代碼)" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/08.multiprocessing Manager.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="Other" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="12.深度強化式學習(自學習代碼)" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Refered Testing" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="C:\Users\20613\Desktop\12.深度強化式學習(自學習代碼)\Refered Testing\01.multiprocessing的使用\08.基於共有的Queue進行通信.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="test" type="PythonConfigurationType" factoryName="Python" temporary="true">
      <module name="12.深度強化式學習(自學習代碼)" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Chapter05 演員評論家模型與分佈式訓練" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Chapter05 演員評論家模型與分佈式訓練/test.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <recent_temporary>
      <list>
        <item itemvalue="Python.01.reinforce演算法" />
        <item itemvalue="Python.test" />
        <item itemvalue="Python.08.基於共有的Queue進行通信" />
        <item itemvalue="Python.Other" />
        <item itemvalue="Python.08.multiprocessing Manager" />
      </list>
    </recent_temporary>
  </component>
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="db5997fe-08b4-47f5-9f96-e6576667bebe" name="Default Changelist" comment="" />
      <created>1642320304196</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1642320304196</updated>
      <workItem from="1642320307046" duration="518000" />
      <workItem from="1642320861008" duration="11178000" />
      <workItem from="1642337689100" duration="2011000" />
      <workItem from="1642380421642" duration="29405000" />
      <workItem from="1642475262796" duration="26303000" />
      <workItem from="1642559781722" duration="8389000" />
      <workItem from="1642577458046" duration="4298000" />
      <workItem from="1642589693236" duration="610000" />
      <workItem from="1645769783786" duration="761000" />
      <workItem from="1646103624760" duration="29000" />
    </task>
    <servers />
  </component>
  <component name="TestHistory">
    <history-entry file="pytest_in_1_py - 2022.01.17 at 18h 46m 56s.xml">
      <configuration name="pytest in 1.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_in_04_測試Q網路_py - 2022.01.17 at 18h 48m 08s.xml">
      <configuration name="pytest in 04.測試Q網路.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_in_04_測試Q網路_py - 2022.01.17 at 18h 48m 16s.xml">
      <configuration name="pytest in 04.測試Q網路.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_in_04_測試Q網路_py - 2022.01.17 at 18h 49m 26s.xml">
      <configuration name="pytest in 04.測試Q網路.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_in_04_測試Q網路_py - 2022.01.17 at 18h 51m 28s.xml">
      <configuration name="pytest in 04.測試Q網路.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_in_04_測試Q網路_py - 2022.01.17 at 18h 52m 33s.xml">
      <configuration name="pytest in 04.測試Q網路.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_in_04_測試Q網路_py - 2022.01.17 at 18h 56m 04s.xml">
      <configuration name="pytest in 04.測試Q網路.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_in_1_py - 2022.01.17 at 19h 04m 15s.xml">
      <configuration name="pytest in 1.py" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_for_1_test_model - 2022.01.17 at 19h 05m 06s.xml">
      <configuration name="pytest for 1.test_model" configurationId="tests" />
    </history-entry>
    <history-entry file="pytest_for_1_test_model - 2022.01.17 at 19h 05m 22s.xml">
      <configuration name="pytest for 1.test_model" configurationId="tests" />
    </history-entry>
  </component>
  <component name="TimeTrackingManager">
    <option name="totallyTimeSpent" value="83502000" />
  </component>
  <component name="TodoView">
    <todo-panel id="selected-file">
      <is-autoscroll-to-source value="true" />
    </todo-panel>
    <todo-panel id="all">
      <are-packages-shown value="true" />
      <is-autoscroll-to-source value="true" />
    </todo-panel>
  </component>
  <component name="ToolWindowManager">
    <frame x="1912" y="-8" width="1936" height="1056" extended-state="6" />
    <layout>
      <window_info active="true" content_ui="combo" id="Project" order="0" visible="true" weight="0.18676628" />
      <window_info id="Structure" order="1" side_tool="true" weight="0.25" />
      <window_info id="Favorites" order="2" side_tool="true" />
      <window_info anchor="bottom" id="Message" order="0" />
      <window_info anchor="bottom" id="Find" order="1" />
      <window_info anchor="bottom" id="Run" order="2" sideWeight="0.4994664" weight="0.267101" />
      <window_info anchor="bottom" id="Debug" order="3" weight="0.3984799" />
      <window_info anchor="bottom" id="Cvs" order="4" weight="0.25" />
      <window_info anchor="bottom" id="Inspection" order="5" weight="0.4" />
      <window_info anchor="bottom" id="TODO" order="6" weight="0.32899022" />
      <window_info anchor="bottom" id="Database Changes" order="7" />
      <window_info anchor="bottom" id="Version Control" order="8" />
      <window_info anchor="bottom" id="Terminal" order="9" weight="0.28230184" />
      <window_info anchor="bottom" id="Event Log" order="10" sideWeight="0.50053364" side_tool="true" weight="0.32899022" />
      <window_info anchor="bottom" id="Python Console" order="11" weight="0.32899022" />
      <window_info anchor="bottom" id="Docker" order="12" show_stripe_button="false" />
      <window_info anchor="bottom" id="Jupyter" order="13" weight="0.32899022" />
      <window_info anchor="right" id="Commander" internal_type="SLIDING" order="0" type="SLIDING" weight="0.4" />
      <window_info anchor="right" id="Ant Build" order="1" weight="0.25" />
      <window_info anchor="right" content_ui="combo" id="Hierarchy" order="2" weight="0.25" />
      <window_info anchor="right" id="SciView" order="3" weight="0.13874066" />
      <window_info anchor="right" id="R Packages" order="4" />
      <window_info anchor="right" id="Database" order="5" />
      <window_info anchor="right" id="R Graphics" order="6" />
    </layout>
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="1" />
  </component>
  <component name="com.intellij.coverage.CoverageDataManagerImpl">
    <SUITE FILE_PATH="coverage/12___$04_record.coverage" NAME="04.更新record內容 Coverage Results" MODIFIED="1642328226795" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程" />
    <SUITE FILE_PATH="coverage/12___$06_.coverage" NAME="06.解決多臂拉霸機問題 Coverage Results" MODIFIED="1642330886707" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程" />
    <SUITE FILE_PATH="coverage/12___$02_Q.coverage" NAME="02.利用神經網絡扮演Q函數的角色 Coverage Results" MODIFIED="1642414748844" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network" />
    <SUITE FILE_PATH="coverage/12___$05_____.coverage" NAME="05.進程同步 -- 加鎖 Coverage Results" MODIFIED="1642515528535" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$01_OpenAI_Gym.coverage" NAME="01.使用OpenAI Gym Coverage Results" MODIFIED="1642508043852" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略" />
    <SUITE FILE_PATH="coverage/12___$08_softmax.coverage" NAME="08.使用softmax解決多臂拉霸機問題 Coverage Results" MODIFIED="1642336663307" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/多臂拉霸機問題" />
    <SUITE FILE_PATH="coverage/12___$02_.coverage" NAME="02.測試網絡 Coverage Results" MODIFIED="1642496234570" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性" />
    <SUITE FILE_PATH="coverage/12___$07_Queue.coverage" NAME="07.基於Queue進行進程通信 Coverage Results" MODIFIED="1642519056618" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$pytest_in_04_Q_py.coverage" NAME="pytest in 04.測試Q網路.py Coverage Results" MODIFIED="1642416963130" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network" />
    <SUITE FILE_PATH="coverage/12___$1.coverage" NAME="1 Coverage Results" MODIFIED="1642417648630" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network" />
    <SUITE FILE_PATH="coverage/12___$04_Q__1_.coverage" NAME="04.測試Q網路 (1) Coverage Results" MODIFIED="1642427509577" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索" />
    <SUITE FILE_PATH="coverage/12___$06_Pool.coverage" NAME="06.進程池化基於Pool Coverage Results" MODIFIED="1642516210586" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$02_ID.coverage" NAME="02.打印運行中進程的ID Coverage Results" MODIFIED="1642513079582" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$05_DQN.coverage" NAME="05.包含經驗回放的DQN Coverage Results" MODIFIED="1642427543916" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索" />
    <SUITE FILE_PATH="coverage/12___$06___1_.coverage" NAME="06.解決多臂拉霸機問題 (1) Coverage Results" MODIFIED="1642336462814" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/多臂拉霸機問題" />
    <SUITE FILE_PATH="coverage/12___$07_softmax.coverage" NAME="07.softmax函式 Coverage Results" MODIFIED="1642337734122" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/01.01 多臂拉霸機問題" />
    <SUITE FILE_PATH="coverage/12___$08_Queue.coverage" NAME="08.基於共有的Queue進行通信 Coverage Results" MODIFIED="1642560022737" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$01_example01.coverage" NAME="01.example01 Coverage Results" MODIFIED="1642512142753" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$04_6X6DQN.coverage" NAME="04.6X6方格遊戲下的DQN Coverage Results" MODIFIED="1642496765053" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性" />
    <SUITE FILE_PATH="coverage/12___$00_Pre.coverage" NAME="00.Pre Coverage Results" MODIFIED="1642321054857" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter01 強化式學習的基本觀念" />
    <SUITE FILE_PATH="coverage/12___$pytest_in_1_py.coverage" NAME="pytest in 1.py Coverage Results" MODIFIED="1642417450262" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network" />
    <SUITE FILE_PATH="coverage/12___$04_Q.coverage" NAME="04.測試Q網路 Coverage Results" MODIFIED="1642419016861" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network" />
    <SUITE FILE_PATH="coverage/12___$03_.coverage" NAME="03.數據共享 Coverage Results" MODIFIED="1642514322582" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$01_Gridworld.coverage" NAME="01.建立一個Gridworld遊戲 Coverage Results" MODIFIED="1642392594792" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network" />
    <SUITE FILE_PATH="coverage/12___$01_reinforce.coverage" NAME="01.reinforce演算法 Coverage Results" MODIFIED="1642582843861" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.04 REINFORCE演算法" />
    <SUITE FILE_PATH="coverage/12___$test.coverage" NAME="test Coverage Results" MODIFIED="1642579876362" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter05 演員評論家模型與分佈式訓練" />
    <SUITE FILE_PATH="coverage/12___$04_____.coverage" NAME="04.進程同步 -- 不設置同步機制 Coverage Results" MODIFIED="1642515247278" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$01_.coverage" NAME="01.目標網絡 Coverage Results" MODIFIED="1642494646566" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性" />
    <SUITE FILE_PATH="coverage/12___$01_Pytorch.coverage" NAME="01.Pytorch的自動微分與模型建構 Coverage Results" MODIFIED="1642338540763" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡" />
    <SUITE FILE_PATH="coverage/12___$Other.coverage" NAME="Other Coverage Results" MODIFIED="1642519650729" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing" />
    <SUITE FILE_PATH="coverage/12___$08_multiprocessing_Manager.coverage" NAME="08.multiprocessing Manager Coverage Results" MODIFIED="1642519316338" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用" />
    <SUITE FILE_PATH="coverage/12___$pytest_for_1_test_model.coverage" NAME="pytest for 1.test_model Coverage Results" MODIFIED="1642417519696" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter03 Deep Q-Network" />
    <SUITE FILE_PATH="coverage/12___$04_.coverage" NAME="04.解决广告推送问题 Coverage Results" MODIFIED="1642386912567" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡" />
  </component>
  <component name="editorHistoryManager">
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/02.自動微分.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="240">
          <caret line="10" column="8" lean-forward="true" selection-start-line="10" selection-start-column="8" selection-end-line="10" selection-end-column="8" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/01.Pytorch中的張量.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="216">
          <caret line="9" selection-start-line="9" selection-end-line="9" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter01 強化式學習的基本觀念/01.Pre.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="96">
          <caret line="4" selection-start-line="4" selection-end-line="4" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/01.利用平均(期望)獎金找出最佳動作.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="264">
          <caret line="11" lean-forward="true" selection-start-line="11" selection-end-line="11" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/02.設定ε值以及不同拉霸機的中獎率.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="240">
          <caret line="10" lean-forward="true" selection-start-line="10" selection-end-line="10" />
          <folding>
            <element signature="e#1#19#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/03.把中獎幾率轉化成中獎金額.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="264">
          <caret line="11" lean-forward="true" selection-start-line="11" selection-end-line="11" />
          <folding>
            <element signature="e#0#13#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/04.更新record內容.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="96">
          <caret line="4" column="41" lean-forward="true" selection-start-line="4" selection-start-column="41" selection-end-line="4" selection-end-column="41" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/05.找出最佳動作.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="120">
          <caret line="5" column="20" lean-forward="true" selection-start-line="5" selection-start-column="20" selection-end-line="5" selection-end-column="20" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.03 使用PyTorch建構神經網絡/03.建構模型.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="648">
          <caret line="27" column="20" lean-forward="true" selection-start-line="27" selection-start-column="20" selection-end-line="27" selection-end-column="20" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/07.softmax函式.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="48">
          <caret line="2" lean-forward="true" selection-start-line="2" selection-end-line="2" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/01.建立一個Gridworld遊戲.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="216">
          <caret line="9" column="54" selection-start-line="9" selection-start-column="54" selection-end-line="9" selection-end-column="54" />
        </state>
      </provider>
    </entry>
    <entry file="file://$APPLICATION_HOME_DIR$/helpers/pycharm/_jb_pytest_runner.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="72">
          <caret line="3" selection-start-line="3" selection-end-line="3" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/Anaconda3/envs/pytorch/Lib/site-packages/torch/nn/modules/loss.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="157">
          <caret line="519" column="26" lean-forward="true" selection-start-line="519" selection-start-column="26" selection-end-line="519" selection-end-column="26" />
        </state>
      </provider>
    </entry>
    <entry file="file://D:/Anaconda3/envs/pytorch/Lib/importlib/__init__.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="165">
          <caret line="126" selection-start-line="126" selection-end-line="126" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/03.運算圖.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="312">
          <caret line="13" column="16" lean-forward="true" selection-start-line="13" selection-start-column="16" selection-end-line="13" selection-end-column="16" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/1.py" />
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/buffer.py" />
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/GridBoard.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-1218">
          <caret line="18" column="24" lean-forward="true" selection-start-line="18" selection-start-column="24" selection-end-line="18" selection-end-column="24" />
          <folding>
            <element signature="e#0#18#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/06.解決多臂拉霸機問題.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="1080">
          <caret line="45" column="30" lean-forward="true" selection-start-line="45" selection-start-column="30" selection-end-line="45" selection-end-column="30" />
          <folding>
            <element signature="e#1#19#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.04 解决广告推送问题/01.解决广告推送问题.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="343">
          <caret line="94" column="24" lean-forward="true" selection-start-line="94" selection-start-column="24" selection-end-line="94" selection-end-column="24" />
          <folding>
            <element signature="e#0#18#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/02.利用神經網絡扮演Q函數的角色.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="1800">
          <caret line="75" column="27" lean-forward="true" selection-start-line="75" selection-start-column="27" selection-end-line="75" selection-end-column="27" />
          <folding>
            <element signature="e#0#18#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/Gridworld.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="-1217">
          <caret line="46" lean-forward="true" selection-start-line="46" selection-end-line="46" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.03 避免灾难性失忆的发生 经验回放/Gridworld.py">
      <provider selected="true" editor-type-id="text-editor" />
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/Gridworld.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="48">
          <caret line="2" column="16" lean-forward="true" selection-start-line="2" selection-start-column="16" selection-end-line="2" selection-end-column="16" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/1.py" />
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/02.測試網絡.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="679">
          <caret line="150" column="38" selection-start-line="150" selection-start-column="38" selection-end-line="150" selection-end-column="38" />
          <folding>
            <element signature="e#0#12#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/01.目標網絡.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="353">
          <caret line="90" column="5" lean-forward="true" selection-start-line="90" selection-start-column="5" selection-end-line="90" selection-end-column="5" />
          <folding>
            <element signature="e#0#12#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://D:/Anaconda3/envs/pytorch/Lib/site-packages/torch/nn/modules/linear.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="221">
          <caret line="102" selection-start-line="102" selection-end-line="102" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/CH05.ipynb" />
    <entry file="file://$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/.idea/test.py" />
    <entry file="file://D:/Anaconda3/envs/pytorch/Lib/site-packages/gym/__init__.py">
      <provider selected="true" editor-type-id="text-editor">
        <state>
          <folding>
            <element signature="e#0#21#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/01.簡單案例 -- 平方 立方計算.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="312">
          <caret line="13" selection-start-line="13" selection-end-line="13" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/02.打印運行中進程的ID.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="441">
          <caret line="38" column="4" selection-start-line="38" selection-start-column="4" selection-end-line="38" selection-end-column="4" />
          <folding>
            <element signature="e#32#54#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/03.數據共享.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="648">
          <caret line="27" column="20" lean-forward="true" selection-start-line="27" selection-start-column="20" selection-end-line="27" selection-end-column="20" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/03.對撞墻進行避免.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="3744">
          <caret line="156" column="13" lean-forward="true" selection-start-line="156" selection-start-column="13" selection-end-line="156" selection-end-column="13" />
          <folding>
            <element signature="e#0#12#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/06.進程池化基於Pool.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="408">
          <caret line="17" column="13" selection-start-line="17" selection-start-column="13" selection-end-line="17" selection-end-column="13" />
          <folding>
            <element signature="e#0#22#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://D:/Anaconda3/envs/pytorch/Lib/multiprocessing/pool.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="230">
          <caret line="770" selection-start-line="770" selection-end-line="770" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/08.multiprocessing Manager.py" />
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/08.基於共有的Queue進行通信.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="456">
          <caret line="19" column="19" lean-forward="true" selection-start-line="19" selection-start-column="19" selection-end-line="19" selection-end-column="19" />
          <folding>
            <element signature="e#0#18#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/04.進程同步 -- 不設置同步機制.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="912">
          <caret line="38" column="14" lean-forward="true" selection-start-line="38" selection-start-column="14" selection-end-line="38" selection-end-column="14" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.03 使用OpenAI Gym/01.使用OpenAI Gym.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="336">
          <caret line="14" column="56" lean-forward="true" selection-start-line="14" selection-start-column="56" selection-end-line="14" selection-end-column="56" />
          <folding>
            <element signature="e#0#20#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/05.進程同步 -- 加鎖.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="384">
          <caret line="16" column="44" lean-forward="true" selection-start-line="16" selection-start-column="44" selection-end-line="16" selection-end-column="44" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter05 演員評論家模型與分佈式訓練/test.py" />
    <entry file="file://$PROJECT_DIR$/Refered Testing/01.multiprocessing的使用/07.基於Queue進行進程通信.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="361">
          <caret line="24" column="14" selection-start-line="24" selection-start-column="14" selection-end-line="24" selection-end-column="14" />
          <folding>
            <element signature="e#0#41#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter05 演員評論家模型與分佈式訓練/Note">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="48">
          <caret line="2" column="39" selection-start-line="2" selection-start-column="39" selection-end-line="2" selection-end-column="39" />
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter02 模型化強化式學習問題 馬爾科夫決策過程/02.01 多臂拉霸機問題/08.使用softmax解決多臂拉霸機問題.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="1440">
          <caret line="63" column="14" selection-start-line="63" selection-start-column="14" selection-end-line="63" selection-end-column="14" />
          <folding>
            <element signature="e#1#19#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.02 利用Q-Learning進行探索/04.測試Q網路.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="5712">
          <caret line="242" column="11" selection-start-line="242" selection-start-column="11" selection-end-line="242" selection-end-column="11" />
          <folding>
            <element signature="e#0#18#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.03 避免灾难性失忆的发生 经验回放/01.包含經驗回放的DQN.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="2160">
          <caret line="95" column="10" selection-start-line="95" selection-start-column="10" selection-end-line="95" selection-end-column="10" />
          <folding>
            <element signature="e#0#18#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter03 Deep Q-Network/03.04 使用目標網絡來提升學習的穩定性/04.6X6方格遊戲下的DQN.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="3816">
          <caret line="165" column="20" selection-start-line="165" selection-start-column="20" selection-end-line="165" selection-end-column="20" />
          <folding>
            <element signature="e#0#12#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
    <entry file="file://$PROJECT_DIR$/Chapter04 利用策略梯度法選擇最佳策略/04.04 REINFORCE演算法/01.reinforce演算法.py">
      <provider selected="true" editor-type-id="text-editor">
        <state relative-caret-position="343">
          <caret line="81" column="34" selection-start-line="81" selection-start-column="34" selection-end-line="81" selection-end-column="34" />
          <folding>
            <element signature="e#0#10#0" expanded="true" />
          </folding>
        </state>
      </provider>
    </entry>
  </component>
</project>