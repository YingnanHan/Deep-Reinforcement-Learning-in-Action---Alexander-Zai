{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaper 8 - Intrinsic Curiosity Module\n",
    "#### Deep Reinforcement Learning *in Action*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from nes_py.wrappers import JoypadSpace #A\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT #B\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, COMPLEX_MOVEMENT) #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] 无法在设置线程模式后对其加以更改。\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "done = True\n",
    "for step in range(2500): #D\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize #A\n",
    "import numpy as np\n",
    "\n",
    "def downscale_obs(obs, new_size=(42,42), to_gray=True):\n",
    "    if to_gray:\n",
    "        return resize(obs, new_size, anti_aliasing=True).max(axis=2) #B\n",
    "    else:\n",
    "        return resize(obs, new_size, anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c12da26fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD6CAYAAABnLjEDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAr7UlEQVR4nO2deZRcd5Xfv7f2qt6qN7V6U2uxJEtItrzgTQZ7bBbjMZjlMIE5mZiEjMmZcQLMwGAyJxnISTLOhCXkkAOBDINnMkB8AGMfYzDGGDyAd0uyJbe1b72v1d21dK2//NElo+rvLavdLXVLfvdzjk6rb7/f+y3v3XpV37q/e8U5B8Mw3vj4VnoAhmEsD+bshuERzNkNwyOYsxuGRzBnNwyPYM5uGB5hSc4uIreIyH4ROSQid5+tQRmGcfaRxX7PLiJ+AAcAvB1AH4BnAXzYOfdytTaBWI0L1jdV2ELTRTrOid4+2+TncZSUA5UpuaBynNYWQDiW476zfAJfgE/g0jzGwCz3UQzpfZcUu19p77gb+OvyZMvnA2o/kudF9vG0UapT5ljktrXRrNpPKscTkhQ/Y0rK9YnU8IACwvcLABQdnzOT4b5DCW6br+P5aOtbpWtIQbfPx6cc58vzzVqM6A6g3euF6LzfJyZQTKbUE+h3wsK4CsAh59wRABCR7wG4HUBVZw/WN2H9HX9WYet6ZIKOc0FlpQEc+nAd2fyzyk2r3MjZVr5SktMXdf2l/dz30Tay1TRlyFbc00C2xlf4Ks2s0d9Upbp5nA37eT1y9dw2fsMQ2QYGmvhAAMFh9q6ak7weqbekyJafZifauf2g2s9zfd3c9zN8HdMdvEZbLj9OtqYwjwcAkvkw2Xa9vI5sPQ+wcw1ez26Qj/N4AtP6NQtPVHk6zSM6yn3XDPErQOIi7ckEBNLcfnxH5TgH/+YrVftfytv4TgAnT/u9r2wzDOM8ZCnOrr2c0UuPiNwpIs+JyHPFjP6qbBjGuWcpzt4H4PT3aF0ABuYf5Jz7hnPuSufclf5ozRK6MwxjKSzlM/uzADaKyDoA/QA+BOAPX6uB8wHFeR+tTtzGnylz9bpoGJxWhJTAwgRGvyIKNRzSjz2ifBqJ9cyQbWfXEbL9BuvJNr6VP3PXxhTVDUBhlj97JmdryRac4bWY+O1qPm6L/m4qkOTP3dlGPq40ECWbv8R9P9/Pn80BQF7mz+eaYKlpL727eng8MV0lC0zxrRxJ8zlHd3DbXNPCFLZCTL/X8nEeU1073y8zu3mBQzPK87aKcOzPcv/1hyrvrRFdJwWwBGd3zhVE5C4AjwDwA/iWc27fYs9nGMa5ZSlPdjjnHgbw8Fkai2EY5xCLoDMMj2DObhgeYUlv418vvjwQG6oUGUrKCIJJPUgh08oCRa6Lo6y2r+egmL4pDnbJJJrVfqLD3H++k0W2xw5tJpvfz+rKdT1HyXYg0ar2XSrx62+ikQWkQpzb1rSk+Xx5PUBpdhOrZG6Wj42e4ACPfB1fh+xQTO2n5yklqq+G59jUy3Oc3MgiYqZNDziZ7eB+tJur2MzXJzLEx82u4fuqvld3l8g421KdLMZFFK10cCffa6WoLhj6anmOpdnKMRV/VF2wtie7YXgEc3bD8Ajm7IbhEczZDcMjmLMbhkdYVjW+FATSqyvVx6ZeDjUcvL7KlsFWJRZQUZCHkhyiub6RJdPZd06r3aTyrAJviQ+TbUQJY72t9UWy3Td4JdmG961S++54gtXi0jq+TMkePi6d4/Fc/KaTZAOA3mPtZIuvVkI86yJk29Q+QrbJWQ6rBYDjH4qTzRVZMQ6MKhv51/AW4o1K3wCQL/F90BDi9l2xBNnGsrxu/679UbIde0uL2ve3+3eSbXyQr6/vMK+Ra2HV3+/XFfVtXbT1BMfv21Dx+6gSIvxq/1X/YhjGGwpzdsPwCObshuERzNkNwyMsq0AHAUqhSvGh/2YWI3bu2K82PzHDIYhvbuE8ZZ3hBNnSSibHrhDnvwOAj9SzCDRW5FjHL41dS7aYj0XEtigLXxNbxtS++wIsAtX1TJLN3xsnWz7O4ZRpRWwEgO4Onvun1j9Ctv+w73ayHRriUN/ikC7QoZHHVPuKMqbrEmRa18RjfOmInvksdpDzABxr4Hurd4oFrEwbi53Pd/D+/GxKX8sbLj5AtrEGTtRyxwceI9uJLIdsfyD+rNrPb9MbyfbV9ZV59ubnizgde7IbhkcwZzcMj2DObhgeYUmf2UXkGIAZAEUABeccR48YhnFesOiKMMCrzn6lc05Xm+ZRX9Phrrn4zgpbto33QY9v1fcshyeVJPmXKfuThzmaaradI/W04wAgfCULQz4f9zM1zSJM6GUWqgq1PO7gJj16z+3mfffb3smC5bMHuAAChPvxT+hrCSVppFvNe9y1/fCi7Nl3OX0tG9t4nnXf5DmOXsrPnfgh7ic8qe/1dj6eT7qNzxkbVnIDKPvrR3ewrRjVfaWo5Bvo/DGvx+hlfM7233Jb/6yecTLwi+fJNvEvK0XiVx74MlJjSrUP2Nt4w/AMS3V2B+BnIvK8iNx5xqMNw1gxlvo9+07n3ICIrALwqIi84px74vQDyi8CdwJAJMRv3wzDWB6W9GR3zg2Uf44AuB9zxR7nH/NqRZhgQM9TZhjGuWfRT3YRqQHgc87NlP//DgD/6bXa5Br8OHFb5dM9s4YjrEIjuhAycxGLbKFmFpWKUyyc1R1UkimO6ULIRI1WGoVN3W/mLYcDAX73EtytVHT5pf4uRyvZ3PsjTmwZVqrmtF/L4xmqVcq9Amiq44jARIrFxVvW9pLtp8e2kK3Qq/eTO8QRYtNc6AVhJZgx2cnPopluPYpNK6ecbeQ1mulhwVKrslt3jM9XjOjPxkxKKedd5AH1PMwJQTVhceAt+kOxNfpm7rutsr1W+voUS3kb3wbgfhE5dZ7vOOd+uoTzGYZxDllK+acjAC49i2MxDOMcYl+9GYZHMGc3DI+wvFtcoyUUtlYKQ5GAEgG3h3PIzcEim3+Axa9sE58zpZTbLcT017p8nKOamnZx35mXOY/b2gMsfI1v576rCSk+JUAsV88ijigRcCf38HiqMdLB89mwepRsB5OcSy09zXnppFuvFdzSliBbUIlGnPhpB9m0NQroFahVYTPXyeJvh7K1N3kZ7wuN/CDOfVQpDx5jXRR9N/H1iQ6ycOxTCtmEeEc0AGDwOnbX0JR+rIY92Q3DI5izG4ZHMGc3DI9gzm4YHsGc3TA8wrKq8a4kKMzb91wsKrW6bxtS2yeOcTLGVb9lVTkyxkpoUFFxc1X25YR38znr+pT64RexXFzcxt8OpDt4PAGOnAQA+Dn6F6Ep5ZuEPJ+z56Ek2QZ36mGs2r77/VezIh5Tar6HT7B6nWtW4lUBFFv5+o4/00a2iPItRKaN5113XFfE06u5n+AQX59Bf5xsPqUajTTy+s5er8vk2Un+dgKKcp/uYVtUWd+WBr2fqQOrySbz/Me9xuPbnuyG4RHM2Q3DI5izG4ZHMGc3DI+wvOGyBYF/uFLc6f45xwsGUrqo1KNU+ABY2Rl5t5JvL8Qhmp0P60kSnZ/bj29hscfP1XYRyPAYVz2vJBXM6nvpU6sV0S/E4ylw5CVm1rGxVKVCSKHA5/TPKOHIB1jFzDcrCTSn9OdGKsvi1+3vfpJsj57kPfu+PU1kK0T1ksShBI8poqRBHWnjcdYf1gRUPl/xWT2MW5Tt57MdSiWcw+xugb18r49WyUHga+F7Jn5gXoUlReB9tX31PxmG8UbCnN0wPII5u2F4hDM6u4h8S0RGRGTvabYmEXlURA6WfypJ2wzDOJ9YiED3bQBfBfD3p9nuBvCYc+4eEbm7/PtnzthZGmjeUykoBJIsZMyu0lWlqXU8XC0KzqeIX6UIR3iNXaILdFrlj3qlxPL0DCsz/jqOiBoaZsElNKQnTiyuY4UlGuO94oUCj33wEhb3gpGM2k/2MIt5Gy7rI9uBOEdt+WMsOLbdr1+zyXScbD977Doej3IdG/qVyMEqlaFrhvia+/KKaHec1z00rSScPMFr3rRXUWQB+IcTZHMZXnfXxZGDkuf7Mt+kJ5wMTirnDFQ+rwMZPZIRWMCTvZwHfv6O/9sB3Fv+/70A3num8xiGsbIs9jN7m3NuEADKPzmdiWEY5xXnXKATkTtF5DkRea6QrZJTyDCMc85inX1YRNoBoPxzpNqBp1eECYSVSBDDMJaFxUbQPQjgDgD3lH8+sJBG0VUZvOnf7q2wDXysm46re35cbR+a4k8LqXYWXKZ7+DWskOLjOn6jCy4zXSx0RX8TJ1upSykz3MvCWdtJTnJYqtWVpolLWczLNvKx9WMsPiU28fliw8r2SwBFRU/LfpETVm4eZMFx+DpW01Ks4wEARAkUlAKP3QWVyDglYHLyUl2ASikJNItKktFiDYuLuY0sEqdqWaDLHNL3RN9y4yGy7Z3ktTzRy+0jI3yvZtYqWSgBSJYvmvNVznH2r6s/vxfy1dt3ATwJYLOI9InIRzHn5G8XkYMA3l7+3TCM85gzPtmdcx+u8qebz/JYDMM4h1gEnWF4BHN2w/AIy7rFNTMaxUtf315hK3AwFWZ64mp7p+T10iqjaMpOoZ6FnYnNehRbul2L3FKi95SdiGOXsIiS/Tf8LYR/t75d0inT8St6TUEJsgrNcOO0kscNAAq1Sn63k0pZa6X0cDihqW5qN8g18PMkNMN9Z5v4BBOXKDnb+vRbNjqqiH6/P0m2xFGO7HYx7js5qlyzDn3/6KOPXE622pPKGJU5hqb5uNhT+hzr+llcTMzLgzg6W+VCwJ7shuEZzNkNwyOYsxuGRzBnNwyPsKwCXaHGYfSqSsHHl+XXG6myS6+oiGxa3rRig1JxoMD95KtVhlY0julreXuhKMfVNXKC/5kxVvKCyjZaAMiv4citmr1KFJzSXCswEQjogk0wpeTZ28YnHb46TrZSUOm8ii7ky7GYl8zztdCEyfCYIu5VKVE828wnCP+Ec9g1KWLn1KYzR6YBQClcpRBGC9tn/ErxEq6IjWCK+5nconaDiUuVdQtU3uvFiH5fAfZkNwzPYM5uGB7BnN0wPII5u2F4BHN2w/AIy1sRpiTwZypfX+Ivs4ra8iKXHp5rryQVTLJ6fegjrWQLjytVVfS8figo+6BDR1gRz63h/fA1IbbFlL3RSOr7zHM5VnFDb+Vkl7NPcvlqn/IlRLqnyt5oJQHnxWu4VPZ7V+8m2y8mLubxFDgHAAAcT3B46nQb78/39fF6aOHR0RFd9k+v5clnm5Tw32F+vjXv4fsqOq5886NcRgAo+fnYyc3sWk7Jb6op74GMPkenfLNSc7jypCMWLmsYhjm7YXgEc3bD8AiLrQjzORHpF5Hd5X+3ntthGoaxVBZbEQYAvuyc+8Lr6s3nUIxViiGTb+LXm8kb9WGV0ppdUdmcIq5cxOGu+ZzeT+3zLCCluljEcUqob0mJ+wwHWSTLVtNR/Er45BEO+5RWZTyNihiX0aveBEK8Rje0HCTbk1MbyPbHq39Ftj/5zp1qP/4cT9S1cd9aFZ7wuBJKXdLDQeN7lCShY7xGUuK+6/dzDO7Jdylr7nQRsqTcRgVlPr6ishaKCFnU0ywgvJZDsadjlfvuS0sJl61SEcYwjAuMpXxmv0tEXiy/zbfCjoZxnrNYZ/8agA0AdgAYBPDFageeXhGmmLSKMIaxUizK2Z1zw865onOuBOCbAK56jWNfrQjjr7WKMIaxUiwqgk5E2k8VdgTwPgB7X+v4V/E7+OsrRaRiiAWkYL8eXRaZUhIqblSquig6VVHZz75uNUemAUB/jKvUxAa4vU/Zl308x6VR6g8okVzKPmYASF3EtmCS5+1XoqxmlQ9Tvlo9gm5rB0fLFR3PZ02U5Zq7XvhDsrUqUWgAMHAbR7Z1rOZEkP0nmsmW28gha2Mdukj20eueINtDfdvINrGboytn1rAYN3sJC7rhvXoVny3vOkC2Xc/yhaw9qVyzVVqpaV1UzSSVMj7z991XD6A7s7OXK8LcCKBFRPoA/BWAG0VkB+ZSKBwD8LEznccwjJVlsRVh/vYcjMUwjHOIRdAZhkcwZzcMj7C8W1whKM2PIlKi0PJNyl5NAG3PKNsTe9mWrWeBI9PKwk7+FT1UqXgti2ez7boANZ+29Sz6jRRZFApN6K+zzU/xONO3cOTUzu6jZKsJsKD13OgatZ8bW/aT7Su/egfZmroTZHtrD5cofuz9m9V+MMpia6aZb7v3X/E82X76g2vIlovrwubfvXgt2fwnue/QtCLydvC1bYor26yv17dej2Vqybb9Cr4+N7/zFbLV+VkIPJDR619/76UryRYeqrxfJG9bXA3D85izG4ZHMGc3DI9gzm4YHkGcq74l7mxT09Lttrz7kxW2+hMsKk2tVSKFADTv5vq2xXoW2ZId3F6UadYfZOELAKY2camY8LRS9aNzYXnGihElz94ePaGZtoVztoVFu0CGRaXBa3g8Tb369Z1ap5VS5uO07ZsNR3ktRnfoUV+N+3mcs3HuO9fAbdue5TVKduqias0wi7ojl/O6adWGcg28RvlmRSRWy4MDbT0cZTgxxaHh91/7dbL95fH3kq0rllD7+fnDV5At214ZITn0n/8nssf61IHak90wPII5u2F4BHN2w/AI5uyG4RHM2Q3DIyxvffYYML6jUvmcuoiVcy1JIQDka1myXf0US8i1A9x2uodDJ0eu4rrpADC9nm01/azs5pTmokTV5utZ7Z2e0lXlsSsVuVip3hI9zO21vqd79LVsuH6YbImn2siW38ThnMkdSlLNaFrtp3AFK+phHw80ptj6a3g8tSfUbtRvRnzKVv74IV7Lvndoxe6VhJExPYy7ITxLtuEZTi7wmWPvJ9u+Vzh3wtarB8kGAKuuYfvm+EjF7w9EeSynsCe7YXgEc3bD8Ajm7IbhERZSEaZbRB4XkV4R2SciHy/bm0TkURE5WP5p6aQN4zzmjOGyItIOoN0594KI1AF4HsB7AXwEwIRz7h4RuRtAo3PuM691rnB3t+v85Ccqbcq+7oYj+t7xdKsS4jnN40+uYQEpX6tU3mjXQ1adUnkmMM3hoG5+sj8ApZCynspLqlMEIACoa2fB8T1rOZ/nsTQnaHz611z/t0aPnIS7iZM+Zl6O83GahNvFol1dLdsAoDHG9lSOxcWpFCdzDP2aw5a1sGcASK/mPzRfNkK24eE42Xo6OQfBWJLDXXN7lZhe6GWkpy/ie9jfyuJZIcML7J/Qk2pq90zX45X97P7VVzCTWGS4rHNu0Dn3Qvn/MwB6AXQCuB3AveXD7sXcC4BhGOcpr+szu4isBXAZgKcBtJ1KJ13+uapKm98ViUhZkQjDWCkW7OwiUgvgBwA+4Zzj7WdVqCgSUWNFIgxjpViQs4tIEHOO/o/OuR+WzcPlz/OnPtfzByTDMM4bFlIkQjCXJ77XOfel0/70IIA7ANxT/vnAGTtLAy27K23JLj4u1aa/Bk1fwtVfJKlMIc7CmyjixqomfT/76P4WNiqaYdObxsmWfJKTS2a6OPJKE/wAIPxsnGz/NMLJFPt/j9coPMm6TKZVV7RiP+cvTwqbObrMp0Qztv2IoxHzMb1aymgTty8oVbZDyic8bY97frMuBIbCHC6XeJoj8JqvZDFucJJDIbubE2T70w89qPZ9Msdi6a21+8g2XuJo0R9P7yDb9793g9pPmDVVFMOV6+t81RNOLiRcdieAPwLwkojsLtv+Peac/D4R+SiAEwA+uIBzGYaxQiykIsyvUb2C1M1ndziGYZwrLILOMDyCObtheIRl3eJaDAPT8xIdagkAg1XKGWuRRVr0UuPj2nZHPudUjxoagHW9HOk028R9F15iYabBsZIXnOHxNBzTt0vW/uYw2aSGFa2NJ5QIrxa2DV6nJ+9UqjPDhRUVcpbHPrqDDwsoJaQBPQFnTR9fi0KM26/7Dm/pTG5jARQAxrewQBhQqnmPj3FUXnQ/r9HhLl7zT574Z2rf797+Itk+Pb6JbC8/vpFsl9zMlXlKl+vCcfIgV56Zba1c4MKv1aYA7MluGJ7BnN0wPII5u2F4BHN2w/AIyyrQ1TRkcOWtlds1941xedpbunvV9geSLKj1PsilgoMzrPo5RT8KzOpCYK6Bl2W2kV8XNVEp1cnnjCk58U6+U+0agWtZ2AkmuR9tG/DkZmW78OEqe0K1tGszrKZFxrnvyCg3TnXq3bT/llWy4M93ka103XaySYYjIYsh/fmklXJuVG6jzBBvry3UcNvAFPdTalTUZAD7Eu1kO3Kc79XYtimyDSQ5TDAW0bdeJ7r5vvz7nf+n4vd/dX/1qHV7shuGRzBnNwyPYM5uGB7BnN0wPII5u2F4hGVV4zOFIPaOViqXM6800XE//slb1PZ5pQKLXwmJ9GVZNQ31cQ3tZKcuIedq+DVQC/sMJlnF1aqyxEbZWApWWXrlW4OcUlFmaoNS47yHVdyRLj2MVWaVBJohHmc+ze39WbaFWGiea1/L/Yx+6mqyFZWo3tjFPWQbv1oPMw43cIjzWIxDXn1NfMMUlSyWpXEeUM0LykZ8AEe387XQ8ieEAnxf9h/nkOvWroTaj8bf9N1S8ftQ7vtVj7Unu2F4BHN2w/AI5uyG4RGWUhHmcyLSLyK7y/9uPffDNQxjsSxEoCsA+PPTK8KIyKPlv33ZOfeFhXbmH/Wj7puV4YERJVSx4RVd7ZnazApdIMuikq/AtuG3sRiXadXFq/QmFnEix1mwme3m42KHOBzTKQKQWmkFQLpDCclUhplv4ASLPe2cADOT16uLrKnn7IXTOU4kObyHRbIcbwmvSu0hvpbFYJxs2QaeZP0JnmPtoH7NfHm+PulVSqjvJC/8xGZeo5KybJqICACb/zuXqy7WKePp5NDYWkXQLURYtAOAeB3P58QvL6r4PacIi6dYSA66QQCnikHMiMipijCGYVxALKUiDADcJSIvisi3qhV2PL0iTD5nFWEMY6VYSkWYrwHYAGAH5p78X9TanV4RJhiyijCGsVIsuiKMc27YOVd0zpUAfBPAVedumIZhLJVFV4QRkfZThR0BvA8A1xWeh/MJCpFKkUGLOPNNs+ABADUDLD6UlP3NY5fyOwh9v7W+1zs4yCKbsFYESXF0WDjB55zYpkSh6YVN4J9V9s23shDoG+Mx9odYACoO6FFfN/3eAbK9kOvmA9/OkYeZY3GySZO+B3v6Bh776ARHuxVzvJbTG3iOvrVVPgoe4mseUirkzHQr0ZGKFwSUbjJteinxqW1x7nuahdaZLiUMU7kFs836fRkd4vnEJivH5NO33ANYWkWYD4vIDswN9xiAjy3gXIZhrBBLqQjz8NkfjmEY5wqLoDMMj2DObhgeYVm3uKIlD/+/rkyIl8hw1NbAjXqlFl89q2SlJIseHWuHyZaeYQGnNqqLSqEAb6McOMFRTTWHOcwqkFaSFyrbREMJtWvM9ihKYJbnWIqwWOTGuSpKtEevLvLk2DqyjfxCUTGVD3AbnmABVYq6qJRt4fLXtT1820mB29cOsdqUGOaqKIAu9M4qQpd/lieUr1OOU7bxam0BYGKLEqk3zs/RxgN8bSe2KNF7G3WBOrGKBepsS+WxheeqK3T2ZDcMj2DObhgewZzdMDyCObtheIRlFehkJADfVyoFm2AXDyFaZetpaYyFKk38GvCxmNb8NPcTmdSjy7SoptDl/LoYUHSU9Goej5ZDLl9lm4CklSirEp9z66XHybb/6bVkywzogtaxKRbzZDMLllo547EdvG6JSxRhEUDtAV731FoWkSJDPO+p6/mcThG+AH09+qc4ojC1j/draeJeZgdfXDfMYjIA5FtZ0M1ykRiEE7wWwRm+NyKP6PflxDZF/D1Yue1bFMH6FPZkNwyPYM5uGB7BnN0wPII5u2F4BHN2w/AIy6rGFyKC8a2V4YFapZVsi75v2KeEMIpSIKT2AIcgjl/JB4YUdR8AVu3i/otRpSZ5F7eNbOIEi5Gn4mSrtmfZp+xnj47yvHsdJ4J0ET7nui2DZAOA48P8jcU1646S7cU4y8p/ve2HZHt8ZovaT2IHq/6js/wNwf7+jWRzU7yfPTqkP5/2z64lW0zZ/52/RPnG4bCSTHSSbaJ/SYRgHZ+zqZ7V/MRtvBbFo7wWwaTeUcNBttUfr/zG4nhGv68Ae7IbhmcwZzcMj2DObhgeYSEVYSIi8oyI7ClXhPl82d4kIo+KyMHyTzWVtGEY5wfiXPUP9MCrCSdrnHPJcpbZXwP4OID3A5hwzt0jIncDaHTOfea1zlUX73I7bvh4hc0pLzfDV1URzp5n4Wy6h4+NjPGcaoY59HJsOwtAgF4NJNuklGfuZhEmP83nDChhkoV6fd9xfJ8SXnp9kmxND3FIZW0fJ3ecWaNXCJltZBEo1cVzjO/ntlOb2Bac0UWlwpt47Be3j5AtU+BFH0tyTLEo1XUAYLKfQ2OlyGNq6FVyAyi3wfQWvl8CSjUZACh1cgLNeANnrJycYDGu/jkOwZ3aodQhB1C3jwc6v2T5wf/3JaSHT6oX44xPdjfHqSsWLP9zAG4HcG/Zfi+A957pXIZhrBwLzRvvL2eWHQHwqHPuaQBtp1JJl3+q6WWsIoxhnB8syNnLxSB2AOgCcJWIbFtoB1YRxjDOD16XGu+cSwD4JYBbAAyLSDswVzACc099wzDOUxZSEaYVQN45lxCRKIC3AfhvAB4EcAeAe8o/HzjTuZxfkK+Z9/qi6C35Tl2gKOxlEccpUkSuno0jb2VbLRdFAQDUDCgllpXwqVwX2+Iv8Ri1veuBdJWlV9Yj/lM+QXSMIwIHr2OxRxMrASDVzWKndLDQNBFVBD5lzYNTuqjqjvPYj+xaT7b0Fo5Cq32J+y7oW8pRq9wyeWUr//QGnndY2SPf9gTPJ9VRpcR3mMeZGGObU5KEpjuU66PkLwCAmW3KJHOVYy8+UF1wX0i4bDuAe0XEj7l3Avc55x4SkScB3CciHwVwAsAHF3AuwzBWiIVUhHkRc2Wa59vHAdx8LgZlGMbZxyLoDMMjmLMbhkdY1i2urrmA0r8Yq7B9+qKf0XH/df8tavuJbbwt06doFukOrQ60skV1OwtSANDyjnE+dobVnp9d8b/J9snOD5BtTy9vR42dWPjSj17F0XajSvO/u/nrZLtrz4fVc25o4K24hwZayeYCmoDEptxWvQZ15EXe1plax+KizPCEMqu47+jmhNpPZn+c+1a2BkdH+PmW2M7jcX4ez2yHsp8aQKiR76PCoJI0MszXsVDLY1zdxWWyAWDoGN//dF9X2YYL2JPdMDyDObtheARzdsPwCObshuERljcHXcGHsUSl0PWpJ/6AD6wSQRRQtp7WHmcRp3AZi08a0wN1qn3gmQ6yFZVtkLf7/phs2b1xsvlqlDEqNgAoBZS5h1gRu2wTV0D5h9HryBaP6cLZFU0nyHZ4l5JUr4b7DiY4uixfRRjKrOb2TZ0Jsm1sGiPbsakmsk1M69VSCq28JTUd4tt71bPc1j9TvYrK6dSv1stfp9JKvrpVLNr5+1msLLWywpwr6OMJjSvr3j0v8tAEOsMwzNkNwyOYsxuGRzBnNwyPsKwCnc/nUBOrFBSmE6x8NfTqw8pxmjEUWPNAKsX7IKWPbWHeVQkAiI4o+dk6WVDToraKdcr22DCLVKF+fY5a+WDfYV6jl5WiCn5lPuFrOBoQAL773NVki/RwJiH/AY4cjA3y+viO66KSKKn2UpMtZNsV5uiwXLtSBrrKDk7fFK+na2bxa3inovIqgXHN1w2TbX0Di4gAsG9sNdkm+uM8xqCSxzDB40kf4fUB9HtLJubdG0revVf7r/oXwzDeUJizG4ZHMGc3DI+wlCIRnxORfhHZXf5367kfrmEYi2UhAl0WwE2nF4kQkZ+U//Zl59wXzt3wDMM4WywkLZUDoBWJeN34fSXURiol443bR/nA7Xr7A+O837pY4jcnpUFWkFv38vnGLtOnIQVWNItdHP5Y/yR/FZBhYRa5NSxJJ7fqZan9EZaGSxMcjtnQzSHBOzu45PJXO59W+/mT/mvIVhfgOfau4gm1RThs9LFn9OziHRv5+l5cz/u1f7OXv13Q9s1XU5vDk3wf+Eb4G5jUJlboI8f5246B/VwGYXSmTe0738gDjXfx9clkWXkvHeF7tRTS70vXzteH8qAG9PsKWFqRCAC4S0ReFJFvWa03wzi/WUqRiK8B2ABgB4BBAF/U2lZUhJnSN2UYhnHuWXSRCOfccPlFoATgmwCuqtLmdxVhGpQIGMMwloWFqPGtIhIv//9UkYhXTlWDKfM+AMqnYsMwzheWUiTiH0RkB+bEumMAPnamExXSQYzuqhQ5BmtYdKuGVlEjHGfRIjTGoZuzSq6+np8q4ZgAxrewYDObZHHFV9Qqx/D52n7GbZOd+uus83HfmXaed2ofSyQP93E88foaXTiL7mfRL7OF13LNahbT9h7tJFtNlXDZqZMs8L08zUJXtJkXLjaiCFVVpOHEZv5DKMHnFCXx6Gwn3wcRJYlkLKLHV2fzfH0/v/VBsr2YWUO2H0Yu5fE8o9ysAAqjfM2K8Xlj127AMkspEvFHZ2prGMb5g0XQGYZHMGc3DI9gzm4YHmFZ97NLEQhOVwoIdUf59SaUrJKMUanSMXqNkoCwiSPWLrqBEyy+0sWVWgDAtXE8gH+Io7GmN3Db7p8rYs9RFrliQ3oMUrKLBbpihNdIKys9wVoPIoeVkssAikrp4/AhNvYPtpPN383rk+pRNq4DiLTzHvnsAU70WVqb5n7yfG2zlyfJBgA1T3MkWmiK1yiQ4fXo+BVHu01urSfbbLOeoDSo6Lx3v/ARsjUcZqE118PXNqBXLEdNP4tvgXlReWPTtp/dMDyPObtheARzdsPwCObshuERljfhZA6oP1YpUiT/YJqOSyR1Uck3yAJSTQdvtwz4WAh5W2sv2Y4k1qn9ZH3cf+uuhUVz5eo5kix5HUeMaYkyAcApFWGKF7PINRNk8Sq+JsHHNekdXbvuCNm0xIk+Re+Z3sURXqUqFW6wh4WuwioW82pjHJ1W9PMcV31fn0/Dc31kS23hda/r43EWoxwBF8woW0Un9GdjehUvUlipujyxjY/LNetloDWSOSXR5zxb4VfV29uT3TA8gjm7YXgEc3bD8Ajm7IbhEZZVoCuGgamLKl9fskdZwJkvOpxCy82VPs7tYz0s+q0NcTUP3+V6aefSFAuBo1ewiBNIaeNkmz/Dttm2KjnolGQ++RmOqgus5wNX17FY2VHPawEAf9XxMNneP8wlqGdO8Po2HePzZVbpz42Q0n1NHx877uN+wpfzfLI79W2mL9/KOeOanuLbW6tQA59ybTN8r0XHdDEtqhTdSa3ivqNDSgRcio9Lr9H7Cc7wuuVr543TSjYbhmHObhgewZzdMDzCgp29nE56l4g8VP69SUQeFZGD5Z+WStowzmNez5P94wBOD0O7G8BjzrmNAB4r/24YxnnKgtR4EekC8PsA/guAPyubbwdwY/n/92IuxfRnXus8LuSQ6arc/PuWS/bTcbuHOaEhACT7WbENTCv74QOsZn76fk6Z5+ecgnPtldyJmqKuKZ/aOUvKKrsmfdNyUUmI6Bvh8F3/EJ/06IG1fL7NHGoLAO955C/I1rqHN2aHVvP6FqJKcshhPVw23cbHJi7nfnwhlsmjYV6jickatZ/ODo5PHdrMCr2Wj9EFeOzxXp735BbdXXLNPHZfLd8I7T/ib1WG1iohsBn9GezL8rEN2yYrfh8J63kFgIU/2f8HgL9AZUGeNufcIACUf/LKGoZx3rCQvPG3ARhxzj2/mA5OrwhTnNGfMoZhnHsW8jZ+J4D3lEsyRwDUi8j/BTAsIu3OucFywYgRrbFz7hsAvgEA4bVdiyoIaRjG0jnjk90591nnXJdzbi2ADwH4hXPunwN4EMAd5cPuAPDAORulYRhLZinhsvcAuE9EPgrgBIAPnrGFD5BopYBwMMEVYZJT+p7l+F5+bYqNcNjp5HQL2aJKlOWqXbpC53/8BbIVbr6CbKUgj0dK/OYl/ARXxvI1N6l9l6Y5RDR31SayjVzOol14kvvW9r0DQOZinvvApSxs1vyaQ0m1NZ9t1OM0fUrkZzDGAp07zuMsPaPcBxv0MOOAEn4cWcdreUnbANkOJfh+KaxVhN9/0iu11CrVcLKN7FqzcSUBpvLJthDT3wB/6AO/JNt9hyrrt7jXeO/8upzdOfdLzKnucM6NA7j59bQ3DGPlsAg6w/AI5uyG4RHM2Q3DI4h7rU/0Z7szkVEAx8u/tgDgTeYXJm+kuQA2n/Od15pPj3NOrYO+rM5e0bHIc865K1ek87PMG2kugM3nfGex87G38YbhEczZDcMjrKSzf2MF+z7bvJHmAth8zncWNZ8V+8xuGMbyYm/jDcMjLLuzi8gtIrJfRA6JyAWX3UZEviUiIyKy9zTbBZmiS0S6ReRxEekVkX0i8vGy/UKdT0REnhGRPeX5fL5svyDnc4qzlRJuWZ1dRPwA/heAdwHYCuDDIrJ1OcdwFvg2gFvm2S7UFF0FAH/unNsC4BoAf1q+HhfqfLIAbnLOXQpgB4BbROQaXLjzOcXZSQnnnFu2fwCuBfDIab9/FsBnl3MMZ2keawHsPe33/QDay/9vB7B/pce4yHk9AODtb4T5AIgBeAHA1RfyfAB0lR36JgAPlW2Lms9yv43vBHDytN/7yrYLnQs+RZeIrAVwGYCncQHPp/yWdzfmkqk86py7oOeDs5gSbrmdXdv0bF8HrDAiUgvgBwA+4ZzT60VdIDjnis65HZh7Il4lIttWeEiLZqkp4eaz3M7eB6D7tN+7AHA2gQuP4XJqLrxWiq7zEREJYs7R/9E598Oy+YKdzymccwnM5V64BRfufE6lhDsG4HsAbjo9JRzw+uaz3M7+LICNIrJOREKYS3P14DKP4VxwQaboEhEB8LcAep1zXzrtTxfqfFpFJF7+fxTA2wC8ggt0Pu5sp4RbAcHhVgAHABwG8JcrLYAsYvzfBTAIII+5dyofBdCMORHlYPln00qPc4FzuR5zH6NeBLC7/O/WC3g+lwDYVZ7PXgD/sWy/IOczb2434ncC3aLmYxF0huERLILOMDyCObtheARzdsPwCObshuERzNkNwyOYsxuGRzBnNwyPYM5uGB7h/wOOvOr1UJdaVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "plt.imshow(downscale_obs(env.render(\"rgb_array\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "\n",
    "def prepare_state(state): #A\n",
    "    return torch.from_numpy(downscale_obs(state, to_gray=True)).float().unsqueeze(dim=0)\n",
    "\n",
    "\n",
    "def prepare_multi_state(state1, state2): #B\n",
    "    state1 = state1.clone()\n",
    "    tmp = torch.from_numpy(downscale_obs(state2, to_gray=True)).float()\n",
    "    state1[0][0] = state1[0][1]\n",
    "    state1[0][1] = state1[0][2]\n",
    "    state1[0][2] = tmp\n",
    "    return state1\n",
    "\n",
    "\n",
    "def prepare_initial_state(state,N=3): #C\n",
    "    state_ = torch.from_numpy(downscale_obs(state, to_gray=True)).float()\n",
    "    tmp = state_.repeat((N,1,1))\n",
    "    return tmp.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(qvalues, eps=None): #A\n",
    "    if eps is not None:\n",
    "        if torch.rand(1) < eps:\n",
    "            return torch.randint(low=0,high=7,size=(1,))\n",
    "        else:\n",
    "            return torch.argmax(qvalues)\n",
    "    else:\n",
    "        return torch.multinomial(F.softmax(F.normalize(qvalues)), num_samples=1) #B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExperienceReplay:\n",
    "    def __init__(self, N=500, batch_size=100):\n",
    "        self.N = N #A\n",
    "        self.batch_size = batch_size #B\n",
    "        self.memory = [] \n",
    "        self.counter = 0\n",
    "        \n",
    "    def add_memory(self, state1, action, reward, state2):\n",
    "        self.counter +=1 \n",
    "        if self.counter % 500 == 0: #C\n",
    "            self.shuffle_memory()\n",
    "            \n",
    "        if len(self.memory) < self.N: #D\n",
    "            self.memory.append( (state1, action, reward, state2) )\n",
    "        else:\n",
    "            rand_index = np.random.randint(0,self.N-1)\n",
    "            self.memory[rand_index] = (state1, action, reward, state2)\n",
    "    \n",
    "    def shuffle_memory(self): #E\n",
    "        shuffle(self.memory)\n",
    "        \n",
    "    def get_batch(self): #F\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            batch_size = len(self.memory)\n",
    "        else:\n",
    "            batch_size = self.batch_size\n",
    "        if len(self.memory) < 1:\n",
    "            print(\"Error: No data in memory.\")\n",
    "            return None\n",
    "        #G\n",
    "        ind = np.random.choice(np.arange(len(self.memory)),batch_size,replace=False)\n",
    "        batch = [self.memory[i] for i in ind] #batch is a list of tuples\n",
    "        state1_batch = torch.stack([x[0].squeeze(dim=0) for x in batch],dim=0)\n",
    "        action_batch = torch.Tensor([x[1] for x in batch]).long()\n",
    "        reward_batch = torch.Tensor([x[2] for x in batch])\n",
    "        state2_batch = torch.stack([x[3].squeeze(dim=0) for x in batch],dim=0)\n",
    "        return state1_batch, action_batch, reward_batch, state2_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phi(nn.Module): #A\n",
    "    def __init__(self):\n",
    "        super(Phi, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y)) #size [1, 32, 3, 3] batch, channels, 3 x 3\n",
    "        y = y.flatten(start_dim=1) #size N, 288\n",
    "        return y\n",
    "\n",
    "class Gnet(nn.Module): #B\n",
    "    def __init__(self):\n",
    "        super(Gnet, self).__init__()\n",
    "        self.linear1 = nn.Linear(576,256)\n",
    "        self.linear2 = nn.Linear(256,12)\n",
    "\n",
    "    def forward(self, state1,state2):\n",
    "        x = torch.cat( (state1, state2) ,dim=1)\n",
    "        y = F.relu(self.linear1(x))\n",
    "        y = self.linear2(y)\n",
    "        y = F.softmax(y,dim=1)\n",
    "        return y\n",
    "\n",
    "class Fnet(nn.Module): #C\n",
    "    def __init__(self):\n",
    "        super(Fnet, self).__init__()\n",
    "        self.linear1 = nn.Linear(300,256)\n",
    "        self.linear2 = nn.Linear(256,288)\n",
    "\n",
    "    def forward(self,state,action):\n",
    "        action_ = torch.zeros(action.shape[0],12) #D\n",
    "        indices = torch.stack( (torch.arange(action.shape[0]), action.squeeze()), dim=0)\n",
    "        indices = indices.tolist()\n",
    "        action_[indices] = 1.\n",
    "        x = torch.cat( (state,action_) ,dim=1)\n",
    "        y = F.relu(self.linear1(x))\n",
    "        y = self.linear2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnetwork, self).__init__()\n",
    "        #in_channels, out_channels, kernel_size, stride=1, padding=0\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.linear1 = nn.Linear(288,100)\n",
    "        self.linear2 = nn.Linear(100,12)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y))\n",
    "        y = y.flatten(start_dim=2)\n",
    "        y = y.view(y.shape[0], -1, 32)\n",
    "        y = y.flatten(start_dim=1)\n",
    "        y = F.elu(self.linear1(y))\n",
    "        y = self.linear2(y) #size N, 12\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':150,\n",
    "    'beta':0.2,\n",
    "    'lambda':0.1,\n",
    "    'eta': 1.0,\n",
    "    'gamma':0.2,\n",
    "    'max_episode_len':100,\n",
    "    'min_progress':15,\n",
    "    'action_repeats':6,\n",
    "    'frames_per_state':3\n",
    "}\n",
    "\n",
    "replay = ExperienceReplay(N=1000, batch_size=params['batch_size'])\n",
    "Qmodel = Qnetwork()\n",
    "encoder = Phi()\n",
    "forward_model = Fnet()\n",
    "inverse_model = Gnet()\n",
    "forward_loss = nn.MSELoss(reduction='none')\n",
    "inverse_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "qloss = nn.MSELoss()\n",
    "all_model_params = list(Qmodel.parameters()) + list(encoder.parameters()) #A\n",
    "all_model_params += list(forward_model.parameters()) + list(inverse_model.parameters())\n",
    "opt = optim.Adam(lr=0.001, params=all_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(q_loss, inverse_loss, forward_loss):\n",
    "    loss_ = (1 - params['beta']) * inverse_loss\n",
    "    loss_ += params['beta'] * forward_loss\n",
    "    loss_ = loss_.sum() / loss_.flatten().shape[0]\n",
    "    loss = loss_ + params['lambda'] * q_loss\n",
    "    return loss\n",
    "\n",
    "def reset_env():\n",
    "    \"\"\"\n",
    "    Reset the environment and return a new initial state\n",
    "    \"\"\"\n",
    "    env.reset()\n",
    "    state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "    return state1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICM(state1, action, state2, forward_scale=1., inverse_scale=1e4):\n",
    "    state1_hat = encoder(state1) #A\n",
    "    state2_hat = encoder(state2)\n",
    "    state2_hat_pred = forward_model(state1_hat.detach(), action.detach()) #B\n",
    "    forward_pred_err = forward_scale * forward_loss(state2_hat_pred, \\\n",
    "                        state2_hat.detach()).sum(dim=1).unsqueeze(dim=1)\n",
    "    pred_action = inverse_model(state1_hat, state2_hat) #C\n",
    "    inverse_pred_err = inverse_scale * inverse_loss(pred_action, \\\n",
    "                                        action.detach().flatten()).unsqueeze(dim=1)\n",
    "    return forward_pred_err, inverse_pred_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_train(use_extrinsic=True):\n",
    "    state1_batch, action_batch, reward_batch, state2_batch = replay.get_batch() \n",
    "    action_batch = action_batch.view(action_batch.shape[0],1) #A\n",
    "    reward_batch = reward_batch.view(reward_batch.shape[0],1)\n",
    "    \n",
    "    forward_pred_err, inverse_pred_err = ICM(state1_batch, action_batch, state2_batch) #B\n",
    "    i_reward = (1. / params['eta']) * forward_pred_err #C\n",
    "    reward = i_reward.detach() #D\n",
    "    if use_explicit: #E\n",
    "        reward += reward_batch \n",
    "    qvals = Qmodel(state2_batch) #F\n",
    "    reward += params['gamma'] * torch.max(qvals)\n",
    "    reward_pred = Qmodel(state1_batch)\n",
    "    reward_target = reward_pred.clone()\n",
    "    indices = torch.stack( (torch.arange(action_batch.shape[0]), \\\n",
    "    action_batch.squeeze()), dim=0)\n",
    "    indices = indices.tolist()\n",
    "    reward_target[indices] = reward.squeeze()\n",
    "    q_loss = 1e5 * qloss(F.normalize(reward_pred), F.normalize(reward_target.detach()))\n",
    "    return forward_pred_err, inverse_pred_err, q_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "exception: access violation reading 0x000000000003C200",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3580/3663986077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstate1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;34m\"\"\"Reset the environment and return the initial observation.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_keys_to_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\time_limit.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;31m# reset the emulator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_backup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\nes_py\\nes_env.py\u001b[0m in \u001b[0;36m_restore\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;34m\"\"\"Restore the backup state into the NES emulator.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_env\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_will_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: exception: access violation reading 0x000000000003C200"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "env.reset()\n",
    "state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "eps=0.15\n",
    "losses = []\n",
    "episode_length = 0\n",
    "switch_to_eps_greedy = 1000\n",
    "state_deque = deque(maxlen=params['frames_per_state'])\n",
    "e_reward = 0.\n",
    "last_x_pos = env.env.env._x_position #A\n",
    "ep_lengths = []\n",
    "use_explicit = False\n",
    "for i in range(epochs):\n",
    "    opt.zero_grad()\n",
    "    episode_length += 1\n",
    "    q_val_pred = Qmodel(state1) #B\n",
    "    if i > switch_to_eps_greedy: #C\n",
    "        action = int(policy(q_val_pred,eps))\n",
    "    else:\n",
    "        action = int(policy(q_val_pred))\n",
    "    for j in range(params['action_repeats']): #D\n",
    "        state2, e_reward_, done, info = env.step(action)\n",
    "        last_x_pos = info['x_pos']\n",
    "        if done:\n",
    "            state1 = reset_env()\n",
    "            break\n",
    "        e_reward += e_reward_\n",
    "        state_deque.append(prepare_state(state2))\n",
    "    state2 = torch.stack(list(state_deque),dim=1) #E\n",
    "    replay.add_memory(state1, action, e_reward, state2) #F\n",
    "    e_reward = 0\n",
    "    if episode_length > params['max_episode_len']: #G\n",
    "        if (info['x_pos'] - last_x_pos) < params['min_progress']:\n",
    "            done = True\n",
    "        else:\n",
    "            last_x_pos = info['x_pos']\n",
    "    if done:\n",
    "        ep_lengths.append(info['x_pos'])\n",
    "        state1 = reset_env()\n",
    "        last_x_pos = env.env.env._x_position\n",
    "        episode_length = 0\n",
    "    else:\n",
    "        state1 = state2\n",
    "    if len(replay.memory) < params['batch_size']:\n",
    "        continue\n",
    "    forward_pred_err, inverse_pred_err, q_loss = minibatch_train(use_extrinsic=False) #H\n",
    "    loss = loss_fn(q_loss, forward_pred_err, inverse_pred_err) #I\n",
    "    loss_list = (q_loss.mean(), forward_pred_err.flatten().mean(),\\\n",
    "    inverse_pred_err.flatten().mean())\n",
    "    losses.append(loss_list)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "state_deque = deque(maxlen=params['frames_per_state'])\n",
    "for step in range(5000):\n",
    "    if done:\n",
    "        env.reset()\n",
    "        state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "    q_val_pred = Qmodel(state1)\n",
    "    action = int(policy(q_val_pred,eps))\n",
    "    state2, reward, done, info = env.step(action)\n",
    "    state2 = prepare_multi_state(state1,state2)\n",
    "    state1=state2\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
